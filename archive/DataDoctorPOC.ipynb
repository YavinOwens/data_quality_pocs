{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faker is used to generate fake data for testing and development purposes. This isnt necessary for the given task, but it can be useful for creating a realistic and consistent dataset for testing purposes for data quality and reliability checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (from -r /workspaces/data_quality_pocs/requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: openpyxl in /home/codespace/.local/lib/python3.12/site-packages (from -r /workspaces/data_quality_pocs/requirements.txt (line 2)) (3.1.5)\n",
      "Requirement already satisfied: xlrd in /home/codespace/.local/lib/python3.12/site-packages (from -r /workspaces/data_quality_pocs/requirements.txt (line 3)) (2.0.1)\n",
      "Collecting Faker (from -r /workspaces/data_quality_pocs/requirements.txt (line 4))\n",
      "  Downloading Faker-28.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->-r /workspaces/data_quality_pocs/requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->-r /workspaces/data_quality_pocs/requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->-r /workspaces/data_quality_pocs/requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->-r /workspaces/data_quality_pocs/requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: et-xmlfile in /home/codespace/.local/lib/python3.12/site-packages (from openpyxl->-r /workspaces/data_quality_pocs/requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r /workspaces/data_quality_pocs/requirements.txt (line 1)) (1.16.0)\n",
      "Downloading Faker-28.1.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Faker\n",
      "Successfully installed Faker-28.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /workspaces/data_quality_pocs/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy data for poc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generated successfully!\n",
      "Successfully read data/hospitals.csv\n",
      "  hospital_id                                     name  \\\n",
      "0          H1       Roberts, Kline and Norris Hospital   \n",
      "1          H2          Rice, Arnold and Smith Hospital   \n",
      "2          H3                  Cowan-Thornton Hospital   \n",
      "3          H4  Ramirez, Gibson and Williamson Hospital   \n",
      "\n",
      "                                            location  \n",
      "0  791 Powell Stravenue\\nNorth Kristinemouth, LA ...  \n",
      "1                        USNS Gonzalez\\nFPO AE 98986  \n",
      "2                           USCGC Ball\\nFPO AE 23482  \n",
      "3  0240 Nicholas Hill Apt. 693\\nKathyville, RI 88959  \n",
      "Successfully read data/clinics.csv\n",
      "  clinic_id                                name  \\\n",
      "0        C1  Hall, Harrington and Jacobs Clinic   \n",
      "1        C2                 Wood-Morales Clinic   \n",
      "2        C3              Nelson and Sons Clinic   \n",
      "3        C4   Holmes, Clements and Booth Clinic   \n",
      "\n",
      "                                            location hospital_id  \n",
      "0   8100 Todd Lodge Suite 043\\nPort Kristi, KY 69723          H2  \n",
      "1               266 Griffin Way\\nPort Troy, NC 85439          H9  \n",
      "2  52769 Sarah Islands Apt. 287\\nWest Tracy, WV 1...          H4  \n",
      "3  635 Robinson Field Suite 142\\nPort Josemouth, ...          H6  \n",
      "Successfully read data/providers.csv\n",
      "  provider_id                name        specialization     associated_with  \\\n",
      "0          P1    Stephanie Wright    Social Care Worker  Social Care Agency   \n",
      "1          P2         Megan Huang  General Practitioner    Provider Company   \n",
      "2          P3         Don Jackson            Bank Staff            Hospital   \n",
      "3          P4  Christopher Hurley         Dermatologist            Hospital   \n",
      "\n",
      "                     organization hospital_id clinic_id  \n",
      "0                         Lee Ltd          H9       NaN  \n",
      "1                 Wright-Stephens         H10       C19  \n",
      "2                     Graves-Gill         NaN       NaN  \n",
      "3  Cummings, Jackson and Martinez         NaN       NaN  \n",
      "Column hospital_id in data/providers.csv converted to string\n",
      "Column clinic_id in data/providers.csv converted to string\n",
      "Successfully read data/patients.csv\n",
      "  patient_id            name date_of_birth  \\\n",
      "0       PAT1  Samantha Brown    1964-06-22   \n",
      "1       PAT2     William Lee    1951-02-08   \n",
      "2       PAT3    Steven Lopez    1980-05-24   \n",
      "3       PAT4  David Thompson    1944-07-31   \n",
      "\n",
      "                                             address                 phone  \\\n",
      "0  99807 Elizabeth View Apt. 954\\nLake Vickibury,...  001-457-769-6017x234   \n",
      "1  6400 Scott Points Apt. 973\\nEast Mikaylaville,...       +1-784-885-3412   \n",
      "2    618 Sarah Fields Suite 387\\nPaulville, IL 34570      001-337-256-9287   \n",
      "3        80126 Morrison Common\\nKnightfort, AR 31432     (661)900-1303x048   \n",
      "\n",
      "                       email assigned_provider_id assigned_hospital_id  \n",
      "0      shannon65@example.org                  P84                  NaN  \n",
      "1  kaylacarrillo@example.net                  P20                   H5  \n",
      "2        whayden@example.org                   P1                   H9  \n",
      "3        karen07@example.org                  P33                   H5  \n",
      "Column assigned_hospital_id in data/patients.csv converted to string\n",
      "Successfully read data/appointments.csv\n",
      "  appointment_id patient_id provider_id            appointment_date  \\\n",
      "0          APPT1     PAT116         P97  2024-03-23 18:02:57.685919   \n",
      "1          APPT2     PAT179         P34  2024-04-21 16:24:40.636420   \n",
      "2          APPT3      PAT24          P6  2024-08-10 13:20:27.575458   \n",
      "3          APPT4     PAT136         P27  2024-08-22 07:02:20.996690   \n",
      "\n",
      "      reason  waiting  waiting_time  \n",
      "0  Follow-up    False             0  \n",
      "1  Follow-up    False             0  \n",
      "2  Follow-up     True            87  \n",
      "3  Emergency    False             0  \n",
      "Successfully read data/medical_assets.csv\n",
      "  asset_id                type                  manufacturer     model  \\\n",
      "0       A1         MRI Machine                    Morrow PLC  seven978   \n",
      "1       A2       Defibrillator  Ferguson, Robbins and Phelps   rise697   \n",
      "2       A3  Ultrasound Machine                 Douglas-Adams   than498   \n",
      "3       A4          CT Scanner                Bridges-Harris   push663   \n",
      "\n",
      "  installation_date             status hospital_id clinic_id  \n",
      "0        2022-11-26  Under Maintenance          H6       C30  \n",
      "1        2024-05-12  Under Maintenance          H5        C4  \n",
      "2        2024-08-24     Out of Service          H7       C21  \n",
      "3        2020-02-13     Out of Service          H1       C22  \n",
      "Successfully read data/workforce.csv\n",
      "  employee_id           name              position hospital_id  salary  \\\n",
      "0          E1  Alexis Taylor  Administrative Staff          H6   20963   \n",
      "1          E2   Marc Mathews                 Nurse         H10   36931   \n",
      "2          E3     Gary Smith            Technician          H8   97401   \n",
      "3          E4  Jennifer Wolf  Administrative Staff          H9   42382   \n",
      "\n",
      "    hire_date  \n",
      "0  2023-07-26  \n",
      "1  2023-09-15  \n",
      "2  2021-05-23  \n",
      "3  2021-07-26  \n",
      "Successfully read data/case_allocations.csv\n",
      "  case_id patient_id provider_id  \\\n",
      "0      C1      PAT34         P36   \n",
      "1      C2     PAT109         P30   \n",
      "2      C3     PAT123         P36   \n",
      "3      C4      PAT76         P88   \n",
      "\n",
      "                                    case_description case_status  \n",
      "0  Budget pass film speak nor huge. Lot lay song ...      Closed  \n",
      "1  Item agent someone building summer pull light....      Closed  \n",
      "2  Keep place huge work. Clear fact glass employe...     Pending  \n",
      "3  Score building economic city happy. Account wa...      Closed  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Data generation functions\n",
    "def generate_hospitals(num_hospitals):\n",
    "    hospitals = []\n",
    "    for i in range(num_hospitals):\n",
    "        hospitals.append({\n",
    "            'hospital_id': f'H{i+1}',\n",
    "            'name': fake.company() + ' Hospital',\n",
    "            'location': fake.address()\n",
    "        })\n",
    "    return pd.DataFrame(hospitals)\n",
    "\n",
    "def generate_clinics(num_clinics, num_hospitals):\n",
    "    clinics = []\n",
    "    for i in range(num_clinics):\n",
    "        clinics.append({\n",
    "            'clinic_id': f'C{i+1}',\n",
    "            'name': fake.company() + ' Clinic',\n",
    "            'location': fake.address(),\n",
    "            'hospital_id': f'H{np.random.randint(1, num_hospitals + 1)}'\n",
    "        })\n",
    "    return pd.DataFrame(clinics)\n",
    "\n",
    "def generate_providers(num_providers, num_hospitals, num_clinics):\n",
    "    providers = []\n",
    "    for i in range(num_providers):\n",
    "        providers.append({\n",
    "            'provider_id': f'P{i+1}',\n",
    "            'name': fake.name(),\n",
    "            'specialization': np.random.choice(['General Practitioner', 'Cardiologist', 'Dermatologist', 'Neurologist', 'Pediatrician', 'Social Care Worker', 'Bank Staff']),\n",
    "            'associated_with': np.random.choice(['Hospital', 'Provider Company', 'Social Care Agency']),\n",
    "            'organization': fake.company(),\n",
    "            'hospital_id': f'H{np.random.randint(1, num_hospitals + 1)}' if np.random.choice([True, False]) else None,\n",
    "            'clinic_id': f'C{np.random.randint(1, num_clinics + 1)}' if np.random.choice([True, False]) else None\n",
    "        })\n",
    "    return pd.DataFrame(providers)\n",
    "\n",
    "def generate_patients(num_patients, providers):\n",
    "    patients = []\n",
    "    provider_ids = providers['provider_id'].tolist()\n",
    "    hospital_ids = providers['hospital_id'].tolist()\n",
    "    for i in range(num_patients):\n",
    "        assigned_provider = np.random.choice(provider_ids)\n",
    "        assigned_hospital = providers.loc[providers['provider_id'] == assigned_provider, 'hospital_id'].values[0]\n",
    "        patients.append({\n",
    "            'patient_id': f'PAT{i+1}',\n",
    "            'name': fake.name(),\n",
    "            'date_of_birth': fake.date_of_birth(minimum_age=0, maximum_age=90),\n",
    "            'address': fake.address(),\n",
    "            'phone': fake.phone_number(),\n",
    "            'email': fake.email(),\n",
    "            'assigned_provider_id': assigned_provider,\n",
    "            'assigned_hospital_id': assigned_hospital\n",
    "        })\n",
    "    return pd.DataFrame(patients)\n",
    "\n",
    "def generate_appointments(num_appointments, providers, patients):\n",
    "    appointments = []\n",
    "    for i in range(num_appointments):\n",
    "        appointment_date = fake.date_time_this_year()\n",
    "        waiting = np.random.choice([True, False])\n",
    "        appointments.append({\n",
    "            'appointment_id': f'APPT{i+1}',\n",
    "            'patient_id': f'PAT{np.random.randint(1, len(patients) + 1)}',\n",
    "            'provider_id': f'P{np.random.randint(1, len(providers) + 1)}',\n",
    "            'appointment_date': appointment_date,\n",
    "            'reason': np.random.choice(['Checkup', 'Follow-up', 'Consultation', 'Emergency']),\n",
    "            'waiting': waiting,\n",
    "            'waiting_time': np.random.randint(0, 120) if waiting else 0\n",
    "        })\n",
    "    return pd.DataFrame(appointments)\n",
    "\n",
    "def generate_medical_assets(num_assets, num_hospitals, num_clinics):\n",
    "    assets = []\n",
    "    for i in range(num_assets):\n",
    "        assets.append({\n",
    "            'asset_id': f'A{i+1}',\n",
    "            'type': np.random.choice(['MRI Machine', 'X-Ray Machine', 'Ultrasound Machine', 'CT Scanner', 'Defibrillator']),\n",
    "            'manufacturer': fake.company(),\n",
    "            'model': fake.word() + str(np.random.randint(100, 999)),\n",
    "            'installation_date': fake.date_this_decade(),\n",
    "            'status': np.random.choice(['Operational', 'Under Maintenance', 'Out of Service']),\n",
    "            'hospital_id': f'H{np.random.randint(1, num_hospitals + 1)}',\n",
    "            'clinic_id': f'C{np.random.randint(1, num_clinics + 1)}'\n",
    "        })\n",
    "    return pd.DataFrame(assets)\n",
    "\n",
    "def generate_workforce(num_employees, num_hospitals):\n",
    "    workforce = []\n",
    "    for i in range(num_employees):\n",
    "        workforce.append({\n",
    "            'employee_id': f'E{i+1}',\n",
    "            'name': fake.name(),\n",
    "            'position': np.random.choice(['Nurse', 'Doctor', 'Technician', 'Administrative Staff']),\n",
    "            'hospital_id': f'H{np.random.randint(1, num_hospitals + 1)}',\n",
    "            'salary': fake.random_number(digits=5, fix_len=True),\n",
    "            'hire_date': fake.date_this_decade()\n",
    "        })\n",
    "    return pd.DataFrame(workforce)\n",
    "\n",
    "def generate_case_allocations(num_cases, providers, patients):\n",
    "    case_allocations = []\n",
    "    for i in range(num_cases):\n",
    "        case_allocations.append({\n",
    "            'case_id': f'C{i+1}',\n",
    "            'patient_id': f'PAT{np.random.randint(1, len(patients) + 1)}',\n",
    "            'provider_id': f'P{np.random.randint(1, len(providers) + 1)}',\n",
    "            'case_description': fake.text(max_nb_chars=200),\n",
    "            'case_status': np.random.choice(['Open', 'Closed', 'Pending'])\n",
    "        })\n",
    "    return pd.DataFrame(case_allocations)\n",
    "\n",
    "def generate_data():\n",
    "    num_hospitals = 10\n",
    "    num_clinics = 30\n",
    "    num_providers = 100\n",
    "    num_patients = 200\n",
    "    num_appointments = 500\n",
    "    num_assets = 50\n",
    "    num_employees = 100\n",
    "    num_cases = 200\n",
    "    \n",
    "    hospitals = generate_hospitals(num_hospitals)\n",
    "    clinics = generate_clinics(num_clinics, num_hospitals)\n",
    "    providers = generate_providers(num_providers, num_hospitals, num_clinics)\n",
    "    patients = generate_patients(num_patients, providers)\n",
    "    appointments = generate_appointments(num_appointments, providers, patients)\n",
    "    medical_assets = generate_medical_assets(num_assets, num_hospitals, num_clinics)\n",
    "    workforce = generate_workforce(num_employees, num_hospitals)\n",
    "    case_allocations = generate_case_allocations(num_cases, providers, patients)\n",
    "\n",
    "    # Create data directory if not exists\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    hospitals.to_csv('data/hospitals.csv', index=False)\n",
    "    clinics.to_csv('data/clinics.csv', index=False)\n",
    "    providers.to_csv('data/providers.csv', index=False)\n",
    "    patients.to_csv('data/patients.csv', index=False)\n",
    "    appointments.to_csv('data/appointments.csv', index=False)\n",
    "    medical_assets.to_csv('data/medical_assets.csv', index=False)\n",
    "    workforce.to_csv('data/workforce.csv', index=False)\n",
    "    case_allocations.to_csv('data/case_allocations.csv', index=False)\n",
    "    print(\"Data generated successfully!\")\n",
    "\n",
    "# Generate data\n",
    "generate_data()\n",
    "\n",
    "# Test case script\n",
    "def test_read_data_files():\n",
    "    DATA_FILES = [\n",
    "        'data/hospitals.csv',\n",
    "        'data/clinics.csv',\n",
    "        'data/providers.csv',\n",
    "        'data/patients.csv',\n",
    "        'data/appointments.csv',\n",
    "        'data/medical_assets.csv',\n",
    "        'data/workforce.csv',\n",
    "        'data/case_allocations.csv'\n",
    "    ]\n",
    "\n",
    "    for file in DATA_FILES:\n",
    "        try:\n",
    "            df = pd.read_csv(file, low_memory=False)\n",
    "            print(f\"Successfully read {file}\")\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(file, encoding='latin-1', low_memory=False)\n",
    "            print(f\"Successfully read {file} with latin-1 encoding\")\n",
    "        \n",
    "        print(df.head(4))\n",
    "        \n",
    "        \n",
    "        # Check and convert data types if needed\n",
    "        for col in df.columns:\n",
    "            if not pd.api.types.is_numeric_dtype(df[col]) and not pd.api.types.is_string_dtype(df[col]):\n",
    "                df[col] = df[col].astype(str)\n",
    "                print(f\"Column {col} in {file} converted to string\")\n",
    "\n",
    "# Run tests\n",
    "test_read_data_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Doctor Function to read data files and perform data cleaning and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'data/data_quality_checks_template.xlsx' created successfully with instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Alignment\n",
    "from difflib import SequenceMatcher\n",
    "from collections import defaultdict\n",
    "\n",
    "def clean_column_names(df):\n",
    "    df.columns = [re.sub(r'\\W+', '_', col).lower() for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def is_pii(column_name):\n",
    "    pii_keywords = [\"name\", \"dob\", \"date of birth\", \"age\", \"contact number\"]\n",
    "    for keyword in pii_keywords:\n",
    "        if similar(column_name.lower(), keyword) > 0.8:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def read_all_structured_files(directory_path):\n",
    "    all_files = glob.glob(os.path.join(directory_path, \"*.csv\")) + glob.glob(os.path.join(directory_path, \"*.xlsx\"))\n",
    "    all_sheets = []\n",
    "    \n",
    "    for file_path in all_files:\n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = clean_column_names(df)\n",
    "            all_sheets.append((file_path, df))\n",
    "        elif file_path.endswith('.xlsx'):\n",
    "            xls = pd.ExcelFile(file_path)\n",
    "            for sheet_name in xls.sheet_names:\n",
    "                df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "                df = clean_column_names(df)\n",
    "                all_sheets.append((f\"{file_path} - {sheet_name}\", df))\n",
    "    \n",
    "    return all_sheets\n",
    "\n",
    "def find_critical_elements(all_sheets):\n",
    "    column_files_map = defaultdict(list)\n",
    "    for file_path, df in all_sheets:\n",
    "        for column in df.columns:\n",
    "            column_files_map[column].append(file_path)\n",
    "    \n",
    "    critical_elements = {column: files for column, files in column_files_map.items() if len(files) > 1}\n",
    "    return critical_elements\n",
    "\n",
    "def configure_quality_check(csv_file_path, excel_file_path=None):\n",
    "    all_sheets = read_all_structured_files(os.path.dirname(csv_file_path))\n",
    "    critical_elements = find_critical_elements(all_sheets)\n",
    "    \n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df = clean_column_names(df)\n",
    "    column_names = df.columns.tolist()\n",
    "\n",
    "    pii_flags = []\n",
    "    critical_data_elements = []\n",
    "    \n",
    "    for column in column_names:\n",
    "        if is_pii(column):\n",
    "            similar_columns = [col for sheet in all_sheets for col in sheet[1].columns if similar(col.lower(), column.lower()) > 0.8]\n",
    "            description = ', '.join(set(similar_columns))\n",
    "            pii_flags.append(f\"Yes, description: {description}\")\n",
    "        else:\n",
    "            pii_flags.append(\"No\")\n",
    "        \n",
    "        if column in critical_elements:\n",
    "            critical_data_elements.append(f\"Yes, files: {', '.join(critical_elements[column])}\")\n",
    "        else:\n",
    "            critical_data_elements.append(\"No\")\n",
    "    \n",
    "    data_quality_checks_df = pd.DataFrame({\n",
    "        \"column_names\": column_names,\n",
    "        \"PII_Flag\": pii_flags,\n",
    "        \"test_completeness\": [\"Not Assessed\" for _ in column_names],  # Set default value to \"Not Assessed\"\n",
    "        \"test_uniqueness\": [\"\" for _ in column_names],\n",
    "        \"test_timeliness\": [\"\" for _ in column_names],\n",
    "        \"test_consistency\": [\"\" for _ in column_names],\n",
    "        \"test_accuracy\": [\"\" for _ in column_names],\n",
    "        \"test_validity\": [\"\" for _ in column_names],\n",
    "        \"critical_data_element\": critical_data_elements\n",
    "    })\n",
    "\n",
    "    if not excel_file_path:\n",
    "        excel_file_path = os.path.join(os.getcwd(), 'data_quality_checks_template.xlsx')\n",
    "\n",
    "    with pd.ExcelWriter(excel_file_path, engine='openpyxl') as writer:\n",
    "        data_quality_checks_df.to_excel(writer, sheet_name='Data Quality Checks', index=False, startrow=1)\n",
    "\n",
    "    # Load the workbook to add the description\n",
    "    workbook = load_workbook(excel_file_path)\n",
    "    sheet = workbook['Data Quality Checks']\n",
    "    \n",
    "    # Add description at the top\n",
    "    description = (f\"File Name: {os.path.basename(csv_file_path)}\\n\"\n",
    "                   \"Please provide 'Yes' or 'No' in the columns below for each data quality check.\")\n",
    "    sheet['A1'] = description\n",
    "    sheet.merge_cells('A1:H1')\n",
    "    sheet['A1'].alignment = Alignment(wrap_text=True, vertical='center')\n",
    "\n",
    "    # Adjust column widths\n",
    "    for col in range(1, sheet.max_column + 1):\n",
    "        max_length = 0\n",
    "        column = get_column_letter(col)\n",
    "        for cell in sheet[column]:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2)\n",
    "        sheet.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "    workbook.save(excel_file_path)\n",
    "    print(f\"Excel file '{excel_file_path}' created successfully with instructions.\")\n",
    "\n",
    "\n",
    "data_file_path = 'data/appointments.csv'\n",
    "template_file_path = 'data/data_quality_checks_template.xlsx'\n",
    "\n",
    "# Configure quality check and create template\n",
    "configure_quality_check(data_file_path, template_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data quality checks in the created Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness analysis results:\n",
      "        Column Name Total Rows Missing Values Non-Missing Values  \\\n",
      "0    appointment_id        N/A            N/A                N/A   \n",
      "1        patient_id        N/A            N/A                N/A   \n",
      "2       provider_id        N/A            N/A                N/A   \n",
      "3  appointment_date        N/A            N/A                N/A   \n",
      "4            reason        N/A            N/A                N/A   \n",
      "5           waiting        N/A            N/A                N/A   \n",
      "6      waiting_time        N/A            N/A                N/A   \n",
      "\n",
      "  Completeness (%)  \n",
      "0     Not Assessed  \n",
      "1     Not Assessed  \n",
      "2     Not Assessed  \n",
      "3     Not Assessed  \n",
      "4     Not Assessed  \n",
      "5     Not Assessed  \n",
      "6     Not Assessed  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Total Rows</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Non-Missing Values</th>\n",
       "      <th>Completeness (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appointment_id</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Not Assessed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_id</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Not Assessed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>provider_id</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Not Assessed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>appointment_date</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Not Assessed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reason</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Not Assessed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>waiting</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Not Assessed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>waiting_time</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Not Assessed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Column Name Total Rows Missing Values Non-Missing Values  \\\n",
       "0    appointment_id        N/A            N/A                N/A   \n",
       "1        patient_id        N/A            N/A                N/A   \n",
       "2       provider_id        N/A            N/A                N/A   \n",
       "3  appointment_date        N/A            N/A                N/A   \n",
       "4            reason        N/A            N/A                N/A   \n",
       "5           waiting        N/A            N/A                N/A   \n",
       "6      waiting_time        N/A            N/A                N/A   \n",
       "\n",
       "  Completeness (%)  \n",
       "0     Not Assessed  \n",
       "1     Not Assessed  \n",
       "2     Not Assessed  \n",
       "3     Not Assessed  \n",
       "4     Not Assessed  \n",
       "5     Not Assessed  \n",
       "6     Not Assessed  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def clean_column_names(df):\n",
    "    df.columns = [re.sub(r'\\W+', '_', col).lower() for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def read_data_quality_template(excel_file_path):\n",
    "    df_template = pd.read_excel(excel_file_path, sheet_name='Data Quality Checks', skiprows=1)\n",
    "    return df_template\n",
    "\n",
    "def assess_completeness(df, column_name):\n",
    "    total_rows = len(df)\n",
    "    missing_values = df[column_name].isnull().sum()\n",
    "    non_missing_values = total_rows - missing_values\n",
    "    completeness_percentage = (non_missing_values / total_rows) * 100\n",
    "\n",
    "    completeness_df = pd.DataFrame({\n",
    "        'Column Name': [column_name],\n",
    "        'Total Rows': [total_rows],\n",
    "        'Missing Values': [missing_values],\n",
    "        'Non-Missing Values': [non_missing_values],\n",
    "        'Completeness (%)': [round(completeness_percentage, 2)]\n",
    "    })\n",
    "\n",
    "    return completeness_df\n",
    "\n",
    "def evaluate_data_quality(data_file_path, template_file_path):\n",
    "    df_template = read_data_quality_template(template_file_path)\n",
    "\n",
    "    if data_file_path.endswith('.csv'):\n",
    "        df_data = pd.read_csv(data_file_path)\n",
    "    elif data_file_path.endswith('.xlsx'):\n",
    "        df_data = pd.read_excel(data_file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use .csv or .xlsx files.\")\n",
    "\n",
    "    completeness_results = pd.DataFrame(columns=['Column Name', 'Total Rows', 'Missing Values', 'Non-Missing Values', 'Completeness (%)'])\n",
    "\n",
    "    if not df_data.empty:\n",
    "        for index, row in df_template.iterrows():\n",
    "            column_name = row['column_names']\n",
    "            test_completeness = str(row['test_completeness']).strip().lower() if pd.notna(row['test_completeness']) else 'not assessed'\n",
    "            if test_completeness == 'yes':\n",
    "                if column_name in df_data.columns:\n",
    "                    completeness_df = assess_completeness(df_data, column_name)\n",
    "                    if not completeness_df.empty:\n",
    "                        completeness_results = pd.concat([completeness_results, completeness_df], ignore_index=True)\n",
    "                else:\n",
    "                    print(f\"Warning: Column '{column_name}' not found in data file.\")\n",
    "            else:\n",
    "                not_assessed_df = pd.DataFrame({\n",
    "                    'Column Name': [column_name],\n",
    "                    'Total Rows': ['N/A'],\n",
    "                    'Missing Values': ['N/A'],\n",
    "                    'Non-Missing Values': ['N/A'],\n",
    "                    'Completeness (%)': ['Not Assessed']\n",
    "                })\n",
    "                completeness_results = pd.concat([completeness_results, not_assessed_df], ignore_index=True)\n",
    "    else:\n",
    "        print(\"Warning: The data file is empty.\")\n",
    "\n",
    "    if completeness_results.empty:\n",
    "        print(\"No completeness analysis results to display.\")\n",
    "    else:\n",
    "        print(\"Completeness analysis results:\")\n",
    "        print(completeness_results)\n",
    "\n",
    "    return completeness_results\n",
    "\n",
    "# Example usage:\n",
    "data_file_path = 'data/appointments.csv'\n",
    "template_file_path = 'data/data_quality_checks_template.xlsx'\n",
    "\n",
    "# Evaluate data quality based on the template\n",
    "completeness_results = evaluate_data_quality(data_file_path, template_file_path)\n",
    "\n",
    "# Display the completeness results DataFrame\n",
    "# print(\"Completeness Results DataFrame:\")\n",
    "# print(completeness_results)\n",
    "completeness_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
